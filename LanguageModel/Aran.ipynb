{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus.reader import CHILDESCorpusReader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.probability import FreqDist\n",
    "corpus = nltk.data.find('/Users/Ershui13/Desktop/ABSTRACT/LanguageModel/Manchester')\n",
    "Aran = CHILDESCorpusReader(corpus, 'Aran/.*.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronounlist=['i', 'me', 'you', 'he' ,'him', 'she', 'her', 'we', 'us', 'they', 'them', 'it']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawsent = Aran.sents(speaker = ['MOT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35477"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rawsent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nom = ['i', 'he', 'she', 'we', 'they']\n",
    "Acc = ['me','him','her','us','them']\n",
    "import re\n",
    "from nltk.util import ngrams\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgram (ngram):\n",
    "    p_gram = []\n",
    "    for gr in ngram:\n",
    "        for p in pronounlist:\n",
    "            if p in gr:\n",
    "                p_gram.append(gr)\n",
    "    return p_gram\n",
    "def save(t,l):\n",
    "    df = pd.DataFrame(t)\n",
    "    df.to_csv(l,sep=',',index=False)\n",
    "\n",
    "def ngram (n,sents):\n",
    "    tempgram = []\n",
    "    for s in sents:\n",
    "        ss = ' '.join(s) \n",
    "        ss = ss.lower()\n",
    "        ss = '<s> ' + ss + ' <\\s>'\n",
    "        tokens = [token for token in ss.split(' ') if token != '']\n",
    "        output = list(ngrams(tokens, n))\n",
    "        tempgram.append(output)\n",
    "        gram = list(itertools.chain(*tempgram))\n",
    "    return gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mot_sent = rawsent\n",
    "Aran_sent = Aran.sents(speaker = ['CHI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Aran_3gram = ngram(3,Aran_sent)\n",
    "Aran_mot_3gram = ngram(3, mot_sent)\n",
    "Aran_p_3gram = pgram(Aran_3gram)\n",
    "Aran_mot_p_3gram = pgram(Aran_mot_3gram)\n",
    "Aran_2gram = ngram(2,Aran_sent )\n",
    "Aran_mot_2gram = ngram(2, mot_sent)\n",
    "Aran_p_2gram = pgram(Aran_2gram)\n",
    "Aran_mot_p_2gram = pgram(Aran_mot_2gram)\n",
    "save(Aran_p_3gram, 'Aran_p_3gram.csv')\n",
    "save(Aran_mot_p_3gram, 'Aran_mot_p_3gram.csv')\n",
    "save(Aran_2gram, 'Aran_2gram.csv')\n",
    "save(Aran_mot_2gram,'Aran_mot_2gram.csv')\n",
    "save(Aran_p_2gram,'Aran_p_2gram.csv')\n",
    "save(Aran_mot_p_2gram,'Aran_mot_p_2gram.csv')\n",
    "save(Aran_3gram, 'Aran_3gram.csv')\n",
    "save(Aran_mot_3gram, 'Aran_mot_3gram.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Aran_mot_aX_Nom = [pair for pair in Aran_mot_p_2gram if pair[1] in Nom]\n",
    "Aran_mot_aX_Acc = [pair for pair in Aran_mot_p_2gram if pair[1] in Acc]\n",
    "Aran_mot_Xb_Nom = [pair for pair in Aran_mot_p_2gram if pair[0] in Nom]\n",
    "Aran_mot_Xb_Acc = [pair for pair in Aran_mot_p_2gram if pair[0] in Acc]\n",
    "Aran_mot_aXNX = [(pair[0], 'X') for pair in Aran_mot_aX_Nom]\n",
    "Aran_mot_aXAX = [(pair[0], 'X') for pair in Aran_mot_aX_Acc]\n",
    "Aran_mot_XbNX = [('X', pair[1]) for pair in Aran_mot_Xb_Nom]\n",
    "Aran_mot_XbAX = [('X', pair[1]) for pair in Aran_mot_Xb_Acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7915"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Aran_mot_Xb_Nom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2274"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Aran_mot_aX_Acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mot_word = Aran.words(speaker = ['MOT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Aran_mot_nom = [word for word in mot_word if word in Nom]\n",
    "Aran_mot_acc = [word for word in mot_word if word in Acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6082"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Aran_mot_nom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2273"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Aran_mot_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
